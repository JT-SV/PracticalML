<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="JT" />

<meta name="date" content="2017-12-08" />

<title>Predicting Barbell Technique Correctness from Accelerometer Data</title>

<script src="PML_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="PML_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="PML_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="PML_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="PML_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="PML_files/navigation-1.1/tabsets.js"></script>
<link href="PML_files/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="PML_files/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Predicting Barbell Technique Correctness from Accelerometer Data</h1>
<h4 class="author"><em>JT</em></h4>
<h4 class="date"><em>16/08/2017</em></h4>

</div>


<div id="synopsis" class="section level2">
<h2>Synopsis</h2>
<p>In this project we attempt to use data from accelerometers placed on the forearm and arm of and on a dumbbell lifted by volunteers to predict how well or poorly they performed barbell lifts. There were five ways (A-E) in which lifts could be performed and an algorithm will be used to predict from the accelerometer data which category their lift falls into.The data will be cleaned, analyzed, and used to train several algorithms on a large training set. The algorithm with the best training-set performance is found. A prediction is made on how well it should perform on a testing set. However, it will not be evaluated on the provided testing set since the testing set does not contain the outcome variable (A-E) and there is no way of evaluating how well the algorithm performs on it. I suspect this part of the exercise is left for the course quiz.</p>
<div id="load-and-clean-the-data" class="section level3">
<h3>Load and clean the data</h3>
<pre class="r"><code>setwd(&quot;~/ds/PracticalMachineLearning/CourseProject&quot;)
rawtraining&lt;-read.csv(&quot;pml-training.csv&quot;,stringsAsFactors=FALSE)
rawtesting&lt;-read.csv(&quot;pml-testing.csv&quot;,stringsAsFactors=FALSE)

# Define non-numeric fields to be left out of the cleaning procedure
leave&lt;-c(&quot;X&quot;,&quot;user_name&quot;,&quot;raw_timestamp_part_1&quot;,&quot;raw_timestamp_part_2&quot;,
          &quot;cvtd_timestamp&quot;,&quot;new_window&quot;,&quot;problem_id&quot;,&quot;num_window&quot;,&quot;classe&quot;)

# Clean up empty spaces, #DIV/0! by turning the string fields into numeric
# This will result in numeric columns, with NA replacing empty spaces and &quot;#DIV/0!&quot;
training&lt;-rawtraining
testing&lt;-rawtesting
for (n in names(rawtraining)){
  if (! n %in% leave){
    suppressWarnings(training[,n]&lt;-as.numeric(training[,n]))
    suppressWarnings(testing[,n]&lt;-as.numeric(testing[,n]))
  }
}

# Take out variables unavailable in the testing set - these columns are NAs in every test case
# and it would be pointless to estimate a model with them only to be unable to apply it 
# to the testing set
usenames&lt;-c()
for (n in names(testing)){
  if (sum(is.na(testing[,n]))&lt;20 &amp; !(n %in% leave)){
    usenames&lt;-c(usenames,n)
  }
}
# Predictors to be used:
print(usenames)</code></pre>
<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            
##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        
##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        
## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       
## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           
## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         
## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         
## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        
## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       
## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;
## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    
## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    
## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   
## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         
## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     
## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     
## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    
## [52] &quot;magnet_forearm_z&quot;</code></pre>
<pre class="r"><code># Add predicted variable to final set of variables to be kept.
usenames&lt;-c(usenames,&quot;classe&quot;)

# Create &quot;cleaner&quot; training/testing sets
training&lt;-training[,which(names(training) %in% usenames)]
testing&lt;-testing[,which(names(testing) %in% usenames)]

# Convert the predicted variable to a factor. Testing does not contain classe..
training$classe&lt;-as.factor(training$classe)
ltrain&lt;-length(names(training))</code></pre>
</div>
<div id="analysis" class="section level3">
<h3>Analysis</h3>
<p>Here we try to make some sense of the predictor variables, massaging the data to iron out anything deemed to make model estimation more difficult.</p>
<p>See if we have any near-zero-variation predictors. We look ok:</p>
<pre class="r"><code>nzv&lt;-nearZeroVar(training,allowParallel=TRUE,saveMetrics = TRUE)
print(paste(&quot;nzv:&quot;,length(nzv$zeroVar)-sum(!nzv$zeroVar)))</code></pre>
<pre><code>## [1] &quot;nzv: 0&quot;</code></pre>
<p>Look at predictor correlations greater than 0.8. We have 19 pairs of super-correlated predictors!</p>
<pre class="r"><code>M&lt;-abs(cor(training[,-ltrain]))
diag(M)&lt;-0
corr_pred&lt;-which(M &gt; 0.8,arr.ind=T)
# Number of correlated pairs of predictors:
print(paste(as.character(c(dim(corr_pred)[1]/2)),&quot;highly correlated predictors&quot;))</code></pre>
<pre><code>## [1] &quot;19 highly correlated predictors&quot;</code></pre>
<p>We take care of this redundant information using Principal Component Analysis. PCs are linearly uncorrelated.</p>
<pre class="r"><code>library(scatterplot3d)
# Get principal components, take a look in 2D: PC1 vs PC2 (we excitedly see five
# clusters at first (b/w version not shown) but then this is confusing when
# we color the plot by predicted &quot;classe&quot; variable
pca&lt;-prcomp(training[,-ltrain],scale=TRUE)
plot(x=pca$x[,1],pca$x[,2],col=training[,&quot;classe&quot;],xlab=&quot;PCA1&quot;,ylab=&quot;PCA2&quot;,main=&quot;PCA1 vs PCA2&quot;)</code></pre>
<p><img src="figures/pca-1.png" width="672" /></p>
<pre class="r"><code># Still hopeful, we plot all predictors&#39; (PC1,PC2,PC3) tuplets. No separation yet 
# but we do see one extreme outlier on in the top right corner
scatterplot3d(x=pca$x[,1],y=pca$x[,2],pca$x[,3],
              color=as.integer(training$classe),
              main=&quot;Scatterplot of PCA1-PCA3&quot;,xlab=&quot;PCA1&quot;,ylab=&quot;PCA2&quot;,zlab=&quot;PCA3&quot;)</code></pre>
<p><img src="figures/pca-2.png" width="672" /></p>
<pre class="r"><code># Let&#39;s take a look at the PCs&#39; distributions to spot any other problems, then nip # the outlier problem in the bud.. 
# I am looking at the gaps between 3rd quartile maximum value.

# Take a look PC3 and PC4&#39;s 3rd Quartile vs. Max - the gap is huge
summary(pca$x)[c(1,2,5,6),]</code></pre>
<pre><code>##       PC1               PC2                 PC3         
##  Min.   :-5.4682   Min.   :-5.853039   Min.   :-5.6482  
##  1st Qu.:-2.6434   1st Qu.:-2.421564   1st Qu.:-1.4764  
##  3rd Qu.: 2.3582   3rd Qu.: 1.108274   3rd Qu.: 1.4814  
##  Max.   : 6.4588   Max.   : 6.319989   Max.   :62.8200  
##       PC4                 PC5                PC6          
##  Min.   : -3.39332   Min.   :-4.63305   Min.   :-11.4810  
##  1st Qu.: -0.48467   1st Qu.:-1.33617   1st Qu.: -1.2706  
##  3rd Qu.:  0.50595   3rd Qu.: 1.17562   3rd Qu.:  1.2576  
##  Max.   :261.30913   Max.   : 7.00631   Max.   :  4.5332  
##       PC7                PC8                PC9          
##  Min.   :-4.25598   Min.   :-4.98311   Min.   :-5.27595  
##  1st Qu.:-1.03052   1st Qu.:-0.94953   1st Qu.:-0.90867  
##  3rd Qu.: 0.94594   3rd Qu.: 0.96488   3rd Qu.: 0.87259  
##  Max.   : 6.24058   Max.   : 7.35815   Max.   : 4.66880  
##       PC10               PC11               PC12         
##  Min.   :-4.35817   Min.   :-6.80306   Min.   :-4.73437  
##  1st Qu.:-0.78251   1st Qu.:-0.80753   1st Qu.:-0.66175  
##  3rd Qu.: 0.79327   3rd Qu.: 0.73847   3rd Qu.: 0.71588  
##  Max.   : 8.91073   Max.   : 4.25937   Max.   : 8.56412  
##       PC13                PC14               PC15         
##  Min.   :-5.421662   Min.   :-6.69370   Min.   :-7.32690  
##  1st Qu.:-0.550669   1st Qu.:-0.36510   1st Qu.:-0.53188  
##  3rd Qu.: 0.565278   3rd Qu.: 0.39900   3rd Qu.: 0.55150  
##  Max.   : 3.338880   Max.   : 7.27024   Max.   : 3.93380  
##       PC16               PC17               PC18         
##  Min.   :-5.21822   Min.   :-3.32809   Min.   :-4.09977  
##  1st Qu.:-0.58395   1st Qu.:-0.48180   1st Qu.:-0.48540  
##  3rd Qu.: 0.56205   3rd Qu.: 0.48995   3rd Qu.: 0.49925  
##  Max.   : 3.53124   Max.   : 3.22050   Max.   :12.15230  
##       PC19               PC20              PC21         
##  Min.   :-3.60072   Min.   :-3.7637   Min.   :-9.35046  
##  1st Qu.:-0.48265   1st Qu.:-0.4247   1st Qu.:-0.41401  
##  3rd Qu.: 0.43712   3rd Qu.: 0.4010   3rd Qu.: 0.41879  
##  Max.   :14.26480   Max.   : 6.5190   Max.   : 2.95516  
##       PC22                PC23               PC24          
##  Min.   :-2.695656   Min.   :-4.62432   Min.   :-3.712585  
##  1st Qu.:-0.379035   1st Qu.:-0.36836   1st Qu.:-0.348012  
##  3rd Qu.: 0.352036   3rd Qu.: 0.35349   3rd Qu.: 0.347093  
##  Max.   : 2.292907   Max.   : 9.52240   Max.   : 4.399247  
##       PC25              PC26                PC27         
##  Min.   :-2.3687   Min.   :-2.124417   Min.   :-2.72798  
##  1st Qu.:-0.3212   1st Qu.:-0.325018   1st Qu.:-0.29751  
##  3rd Qu.: 0.2894   3rd Qu.: 0.296374   3rd Qu.: 0.31115  
##  Max.   : 6.3852   Max.   : 5.337113   Max.   : 2.14260  
##       PC28               PC29               PC30         
##  Min.   :-1.52680   Min.   :-3.84138   Min.   :-4.50620  
##  1st Qu.:-0.27792   1st Qu.:-0.24154   1st Qu.:-0.18443  
##  3rd Qu.: 0.21702   3rd Qu.: 0.25608   3rd Qu.: 0.13375  
##  Max.   : 3.57413   Max.   : 3.52769   Max.   : 6.93362  
##       PC31                PC32               PC33        
##  Min.   :-6.135256   Min.   :-2.20884   Min.   :-4.2000  
##  1st Qu.:-0.206917   1st Qu.:-0.18370   1st Qu.:-0.1817  
##  3rd Qu.: 0.212006   3rd Qu.: 0.21493   3rd Qu.: 0.1669  
##  Max.   : 2.293419   Max.   : 2.19978   Max.   : 2.0483  
##       PC34                PC35               PC36           
##  Min.   :-3.056190   Min.   :-1.61322   Min.   :-2.0884248  
##  1st Qu.:-0.180997   1st Qu.:-0.19298   1st Qu.:-0.1788307  
##  3rd Qu.: 0.185001   3rd Qu.: 0.17969   3rd Qu.: 0.1766828  
##  Max.   : 2.373841   Max.   : 2.76874   Max.   : 2.1145868  
##       PC37               PC38                PC39         
##  Min.   :-1.19219   Min.   :-1.818003   Min.   :-1.60119  
##  1st Qu.:-0.14436   1st Qu.:-0.130710   1st Qu.:-0.14060  
##  3rd Qu.: 0.15040   3rd Qu.: 0.138040   3rd Qu.: 0.11840  
##  Max.   : 2.48569   Max.   : 1.166812   Max.   : 2.35653  
##       PC40               PC41                PC42          
##  Min.   :-2.55321   Min.   :-2.127450   Min.   :-2.156452  
##  1st Qu.:-0.10399   1st Qu.:-0.108752   1st Qu.:-0.101217  
##  3rd Qu.: 0.09650   3rd Qu.: 0.104591   3rd Qu.: 0.105694  
##  Max.   : 1.64514   Max.   : 1.971963   Max.   : 2.883076  
##       PC43               PC44                PC45         
##  Min.   :-0.97105   Min.   :-0.753363   Min.   :-4.55904  
##  1st Qu.:-0.11325   1st Qu.:-0.104302   1st Qu.:-0.08883  
##  3rd Qu.: 0.10112   3rd Qu.: 0.086396   3rd Qu.: 0.07947  
##  Max.   : 1.70853   Max.   : 4.094060   Max.   : 1.76827  
##       PC46                PC47                PC48          
##  Min.   :-1.923984   Min.   :-1.730260   Min.   :-0.654681  
##  1st Qu.:-0.081976   1st Qu.:-0.066358   1st Qu.:-0.080118  
##  3rd Qu.: 0.089974   3rd Qu.: 0.068245   3rd Qu.: 0.078103  
##  Max.   : 0.939582   Max.   : 1.819119   Max.   : 0.774927  
##       PC49                 PC50                PC51          
##  Min.   :-1.8247269   Min.   :-0.989337   Min.   :-0.450801  
##  1st Qu.:-0.0594695   1st Qu.:-0.060171   1st Qu.:-0.043807  
##  3rd Qu.: 0.0605624   3rd Qu.: 0.059298   3rd Qu.: 0.041990  
##  Max.   : 1.6797321   Max.   : 1.159335   Max.   : 0.910153  
##       PC52          
##  Min.   :-0.447172  
##  1st Qu.:-0.020285  
##  3rd Qu.: 0.022113  
##  Max.   : 0.430545</code></pre>
<pre class="r"><code># Track down and get this extreme outlier out. Taking one training case out of 
# 19000+ cases will not matter.
bad_boy&lt;-which(pca$x[,3] &gt; 50)

# Remove the offender and recalculate principal components
training&lt;-training[-bad_boy,]
pca&lt;-prcomp(training[,-ltrain],scale=TRUE)

#Plot again, looks better but it is still difficult to see any separation
scatterplot3d(x=pca$x[,1],y=pca$x[,2],pca$x[,3],
              color=as.integer(training[,&quot;classe&quot;]),
              main=&quot;Scatterplot of PCA1-PCA3&quot;,xlab=&quot;PCA1&quot;,ylab=&quot;PCA2&quot;,zlab=&quot;PCA3&quot;)</code></pre>
<p><img src="figures/pca-3.png" width="672" /></p>
<pre class="r"><code># Without the outlier, re-create the PC weights via preProcess. Not specifying a
# value for pcaComp will leave us the (26) sets of PC weights needed to explain 95%
# of the predictors&#39; variability. The PC weights will be later applied to the 
# testing set.
trainPreProc&lt;-preProcess(training[,-ltrain],method=c(&quot;pca&quot;))
# Apply weights to training set (we won&#39;t do testing yet).
trainPC&lt;-predict(trainPreProc,training[,-ltrain])</code></pre>
</div>
<div id="estimations" class="section level3">
<h3>Estimations</h3>
<p>Trying knn: See if we can somehow group the data, now expressed in terms of PCs into the 5 A-E clusters - not really:</p>
<pre class="r"><code>kMeansPC&lt;-kmeans(trainPC,centers=5)
print(table(as.factor(kMeansPC$cluster),training$classe))</code></pre>
<pre><code>##    
##        A    B    C    D    E
##   1  864  592  489  581  511
##   2 2048 1521 1289 1157 1398
##   3  698  689  493  487  639
##   4  640  506  499  469  497
##   5 1329  489  652  522  562</code></pre>
<div id="some-models" class="section level4">
<h4>Some models…</h4>
<p>Prepare to evaluate a series of models: Add the dependent variable to the dataset</p>
<pre class="r"><code>trainPC$classe&lt;-training$classe</code></pre>
<p>Evaluate Tree and Linear Discriminant Analysis:</p>
<pre class="r"><code># Try rpart (a tree) - results are not good at all:
set.seed(1234)
modRPART&lt;-train(classe~.,data=trainPC,method=&quot;rpart&quot;)
predRPART&lt;-predict(modRPART,trainPC)
table(predRPART,training$classe)</code></pre>
<pre><code>##          
## predRPART    A    B    C    D    E
##         A 5132 2619 3019 1753 2076
##         B    0    0    0    0    0
##         C    0    0    0    0    0
##         D  438  993  383 1263  552
##         E    9  185   20  200  979</code></pre>
<pre class="r"><code># Try linear discriminant analysis - no again:
set.seed(1234)
modLDA&lt;-train(classe~.,data=trainPC,method=&quot;lda&quot;)
predLDA&lt;-predict(modLDA,trainPC)
table(predLDA,training$classe)</code></pre>
<pre><code>##        
## predLDA    A    B    C    D    E
##       A 3651  851  889  252  323
##       B  521 1648  355  587  742
##       C  575  671 1806  481  470
##       D  773  375  259 1588  443
##       E   59  252  113  308 1629</code></pre>
<p>Perhaps we can combine these and another model for consensus prediction. However, let’s first try random forest which already aggregates models:</p>
<pre class="r"><code>set.seed(1234)
modRF&lt;-train(classe~.,data=trainPC,method=&quot;rf&quot;)
predRF&lt;-predict(modRF,trainPC)
table(predRF,training$classe)</code></pre>
<pre><code>##       
## predRF    A    B    C    D    E
##      A 5579    0    0    0    0
##      B    0 3797    0    0    0
##      C    0    0 3422    0    0
##      D    0    0    0 3216    0
##      E    0    0    0    0 3607</code></pre>
<p>This looks extremely promising! Looking at the model we see a tiny Out of Bagging error:</p>
<pre class="r"><code>print(modRF$finalModel)</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 1.62%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 5549   10   13    6    1 0.005377308
## B   39 3716   35    3    4 0.021332631
## C    2   30 3361   27    2 0.017825833
## D    3    1   95 3111    6 0.032649254
## E    0    9   16   16 3566 0.011366787</code></pre>
<p>Let’s do a final estimation of random forest, this time with cross validation:</p>
<pre class="r"><code>set.seed(1234)
modRFcv&lt;-train(classe~.,data=trainPC,method=&quot;rf&quot;,
                        trControl=trainControl(method=&quot;cv&quot;,number=5))
predRFcv&lt;-predict(modRFcv,trainPC)
table(predRFcv,training$classe)</code></pre>
<pre><code>##         
## predRFcv    A    B    C    D    E
##        A 5579    0    0    0    0
##        B    0 3797    0    0    0
##        C    0    0 3422    0    0
##        D    0    0    0 3216    0
##        E    0    0    0    0 3607</code></pre>
<p>The results are identical to the non cv estimation. Let’s inspect the model and confirm that cross-validation was used:</p>
<pre class="r"><code>print(modRFcv)</code></pre>
<pre><code>## Random Forest 
## 
## 19621 samples
##    26 predictors
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 15698, 15697, 15696, 15694, 15699 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.9787473  0.9731162
##   14    0.9755872  0.9691166
##   26    0.9708986  0.9631829
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<p>In the random forest with cv the final model’s Out of Bagging Error is a slightly improved 1.56% (vs 1.62%). For some reason printing the final model for modRFcv shows all 19000+ outcomes so it is omitted here.</p>
</div>
</div>
<div id="resultsconclusion" class="section level3">
<h3>Results/Conclusion</h3>
<p>The best model evaluated was <strong><em>random forest with 5-fold cross-validation</em></strong>. From the literature and the results obtained here it appears that, due to the use of bagging in rf, cross validation does not give much additional benefit. Given the small Out of Bagging error (1.56%), I predict that at most 1 out of the 20 test set cases will be mis-classified by the winning model.</p>
<p>Once again, no testing-set analysis is done since it is impossible to evaluate the accuracy of testing set predictions.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
